{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60e5bd16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-26 21:29:14,950 INFO: generated new fontManager\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import hashlib\n",
    "from datetime import datetime\n",
    "\n",
    "from hops import hdfs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e34412a1",
   "metadata": {},
   "source": [
    "### We will use rides.csv dataset for testing purposes\n",
    "It doesn't have any missing data. Shape = (41078, 11)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98e24d19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/hops/anaconda/envs/theenv/lib/python3.8/site-packages/fsspec/implementations/hdfs.py:83: FutureWarning: pyarrow.hdfs.HadoopFileSystem is deprecated as of 2.0.0, please use pyarrow.fs.HadoopFileSystem instead.\n",
      "  self.client = HadoopFileSystem(\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"hdfs:///Projects/{}/Resources/rides.csv\".format(hdfs.project_name()), index_col=0,\n",
    "                       parse_dates=[\"pickup_datetime\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b031869f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected. Call `.close()` to terminate connection gracefully.\n"
     ]
    }
   ],
   "source": [
    "import hsfs\n",
    "\n",
    "# Create a connection\n",
    "connection = hsfs.connection()\n",
    "\n",
    "# Get the feature store handle for the project's feature store\n",
    "fs = connection.get_feature_store()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "36f31811",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41078, 11)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "381da9b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ride_id</th>\n",
       "      <th>is_start</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>dropoff_datetime</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>taxi_id</th>\n",
       "      <th>driver_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1228</td>\n",
       "      <td>True</td>\n",
       "      <td>1577904560000</td>\n",
       "      <td>0</td>\n",
       "      <td>-73.867676</td>\n",
       "      <td>40.759323</td>\n",
       "      <td>-73.864080</td>\n",
       "      <td>40.763897</td>\n",
       "      <td>3</td>\n",
       "      <td>2013000194</td>\n",
       "      <td>2013000194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>527</td>\n",
       "      <td>True</td>\n",
       "      <td>1577890540000</td>\n",
       "      <td>0</td>\n",
       "      <td>-73.857086</td>\n",
       "      <td>40.772793</td>\n",
       "      <td>-73.807335</td>\n",
       "      <td>40.836117</td>\n",
       "      <td>3</td>\n",
       "      <td>2013000122</td>\n",
       "      <td>2013000122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>394</td>\n",
       "      <td>True</td>\n",
       "      <td>1577887880000</td>\n",
       "      <td>0</td>\n",
       "      <td>-73.844320</td>\n",
       "      <td>40.789043</td>\n",
       "      <td>-73.765950</td>\n",
       "      <td>40.888790</td>\n",
       "      <td>3</td>\n",
       "      <td>2013000102</td>\n",
       "      <td>2013000102</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ride_id  is_start pickup_datetime  dropoff_datetime  pickup_longitude  \\\n",
       "0     1228      True   1577904560000                 0        -73.867676   \n",
       "1      527      True   1577890540000                 0        -73.857086   \n",
       "2      394      True   1577887880000                 0        -73.844320   \n",
       "\n",
       "   pickup_latitude  dropoff_longitude  dropoff_latitude  passenger_count  \\\n",
       "0        40.759323         -73.864080         40.763897                3   \n",
       "1        40.772793         -73.807335         40.836117                3   \n",
       "2        40.789043         -73.765950         40.888790                3   \n",
       "\n",
       "      taxi_id   driver_id  \n",
       "0  2013000194  2013000194  \n",
       "1  2013000122  2013000122  \n",
       "2  2013000102  2013000102  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "867e8c8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 41078 entries, 0 to 41077\n",
      "Data columns (total 11 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   ride_id            41078 non-null  int64  \n",
      " 1   is_start           41078 non-null  bool   \n",
      " 2   pickup_datetime    41078 non-null  object \n",
      " 3   dropoff_datetime   41078 non-null  int64  \n",
      " 4   pickup_longitude   41078 non-null  float64\n",
      " 5   pickup_latitude    41078 non-null  float64\n",
      " 6   dropoff_longitude  41078 non-null  float64\n",
      " 7   dropoff_latitude   41078 non-null  float64\n",
      " 8   passenger_count    41078 non-null  int64  \n",
      " 9   taxi_id            41078 non-null  int64  \n",
      " 10  driver_id          41078 non-null  int64  \n",
      "dtypes: bool(1), float64(4), int64(5), object(1)\n",
      "memory usage: 3.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edbcdf39",
   "metadata": {},
   "source": [
    "#### Here we have numeric, str, bool and datetime (in UNIX format) columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2d1f09",
   "metadata": {},
   "source": [
    "## 1) Create a feature group which does not have event time and partition key.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "adc782b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected. Call `.close()` to terminate connection gracefully.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "78eb74db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.is_start = df.is_start.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6d198723",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ride_id</th>\n",
       "      <th>is_start</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>dropoff_datetime</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>taxi_id</th>\n",
       "      <th>driver_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1228</td>\n",
       "      <td>1</td>\n",
       "      <td>1577904560000</td>\n",
       "      <td>0</td>\n",
       "      <td>-73.867676</td>\n",
       "      <td>40.759323</td>\n",
       "      <td>-73.864080</td>\n",
       "      <td>40.763897</td>\n",
       "      <td>3</td>\n",
       "      <td>2013000194</td>\n",
       "      <td>2013000194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>527</td>\n",
       "      <td>1</td>\n",
       "      <td>1577890540000</td>\n",
       "      <td>0</td>\n",
       "      <td>-73.857086</td>\n",
       "      <td>40.772793</td>\n",
       "      <td>-73.807335</td>\n",
       "      <td>40.836117</td>\n",
       "      <td>3</td>\n",
       "      <td>2013000122</td>\n",
       "      <td>2013000122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>394</td>\n",
       "      <td>1</td>\n",
       "      <td>1577887880000</td>\n",
       "      <td>0</td>\n",
       "      <td>-73.844320</td>\n",
       "      <td>40.789043</td>\n",
       "      <td>-73.765950</td>\n",
       "      <td>40.888790</td>\n",
       "      <td>3</td>\n",
       "      <td>2013000102</td>\n",
       "      <td>2013000102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1366</td>\n",
       "      <td>1</td>\n",
       "      <td>1577907320000</td>\n",
       "      <td>0</td>\n",
       "      <td>-73.860565</td>\n",
       "      <td>40.768370</td>\n",
       "      <td>-73.819430</td>\n",
       "      <td>40.820730</td>\n",
       "      <td>3</td>\n",
       "      <td>2013000059</td>\n",
       "      <td>2013000059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1085</td>\n",
       "      <td>1</td>\n",
       "      <td>1577901700000</td>\n",
       "      <td>0</td>\n",
       "      <td>-73.831210</td>\n",
       "      <td>40.805737</td>\n",
       "      <td>-73.782560</td>\n",
       "      <td>40.867650</td>\n",
       "      <td>3</td>\n",
       "      <td>2013000064</td>\n",
       "      <td>2013000064</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ride_id  is_start pickup_datetime  dropoff_datetime  pickup_longitude  \\\n",
       "0     1228         1   1577904560000                 0        -73.867676   \n",
       "1      527         1   1577890540000                 0        -73.857086   \n",
       "2      394         1   1577887880000                 0        -73.844320   \n",
       "3     1366         1   1577907320000                 0        -73.860565   \n",
       "4     1085         1   1577901700000                 0        -73.831210   \n",
       "\n",
       "   pickup_latitude  dropoff_longitude  dropoff_latitude  passenger_count  \\\n",
       "0        40.759323         -73.864080         40.763897                3   \n",
       "1        40.772793         -73.807335         40.836117                3   \n",
       "2        40.789043         -73.765950         40.888790                3   \n",
       "3        40.768370         -73.819430         40.820730                3   \n",
       "4        40.805737         -73.782560         40.867650                3   \n",
       "\n",
       "      taxi_id   driver_id  \n",
       "0  2013000194  2013000194  \n",
       "1  2013000122  2013000122  \n",
       "2  2013000102  2013000102  \n",
       "3  2013000059  2013000059  \n",
       "4  2013000064  2013000064  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5de68314",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching offline feature group backfill job...\n",
      "Backfill Job started successfully, you can follow the progress at https://hopsworks.glassfish.service.consul:8182/p/123/jobs/named/test1_fg_1_offline_fg_backfill/executions\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<hsfs.core.job.Job at 0x7f6cdf3993d0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test1_fg = fs.create_feature_group(name=\"test1_fg\",\n",
    "                                   version=1,\n",
    "                                   primary_key=[\"ride_id\"],   \n",
    "                                   description=\"test1_fg\")   \n",
    "test1_fg.save(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ef9828",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56248724",
   "metadata": {},
   "source": [
    "## 2) Create a feature group with different primary keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "66595b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"float_pk\"] = np.linspace(0, 1000, num=df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3d9e3cb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ride_id</th>\n",
       "      <th>is_start</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>dropoff_datetime</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>taxi_id</th>\n",
       "      <th>driver_id</th>\n",
       "      <th>float_pk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1228</td>\n",
       "      <td>1</td>\n",
       "      <td>1577904560000</td>\n",
       "      <td>0</td>\n",
       "      <td>-73.867676</td>\n",
       "      <td>40.759323</td>\n",
       "      <td>-73.864080</td>\n",
       "      <td>40.763897</td>\n",
       "      <td>3</td>\n",
       "      <td>2013000194</td>\n",
       "      <td>2013000194</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>527</td>\n",
       "      <td>1</td>\n",
       "      <td>1577890540000</td>\n",
       "      <td>0</td>\n",
       "      <td>-73.857086</td>\n",
       "      <td>40.772793</td>\n",
       "      <td>-73.807335</td>\n",
       "      <td>40.836117</td>\n",
       "      <td>3</td>\n",
       "      <td>2013000122</td>\n",
       "      <td>2013000122</td>\n",
       "      <td>0.024345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>394</td>\n",
       "      <td>1</td>\n",
       "      <td>1577887880000</td>\n",
       "      <td>0</td>\n",
       "      <td>-73.844320</td>\n",
       "      <td>40.789043</td>\n",
       "      <td>-73.765950</td>\n",
       "      <td>40.888790</td>\n",
       "      <td>3</td>\n",
       "      <td>2013000102</td>\n",
       "      <td>2013000102</td>\n",
       "      <td>0.048689</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ride_id  is_start pickup_datetime  dropoff_datetime  pickup_longitude  \\\n",
       "0     1228         1   1577904560000                 0        -73.867676   \n",
       "1      527         1   1577890540000                 0        -73.857086   \n",
       "2      394         1   1577887880000                 0        -73.844320   \n",
       "\n",
       "   pickup_latitude  dropoff_longitude  dropoff_latitude  passenger_count  \\\n",
       "0        40.759323         -73.864080         40.763897                3   \n",
       "1        40.772793         -73.807335         40.836117                3   \n",
       "2        40.789043         -73.765950         40.888790                3   \n",
       "\n",
       "      taxi_id   driver_id  float_pk  \n",
       "0  2013000194  2013000194  0.000000  \n",
       "1  2013000122  2013000122  0.024345  \n",
       "2  2013000102  2013000102  0.048689  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "660466cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FeatureGroupWarning: The ingested dataframe contains upper case letters in feature names: `['float_PK']`. Feature names are sanitized to lower case in the feature store.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching offline feature group backfill job...\n",
      "Backfill Job started successfully, you can follow the progress at https://hopsworks.glassfish.service.consul:8182/p/123/jobs/named/test2_float_fg_1_offline_fg_backfill/executions\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<hsfs.core.job.Job at 0x7f6cdf3ab070>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test2_float_fg = fs.create_feature_group(name=\"test2_float_fg\",\n",
    "                                   version=1,\n",
    "                                   primary_key=[\"float_pk\"],   \n",
    "                                   description=\"test2_float_fg\")   \n",
    "test2_float_fg.save(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef10cd5",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "684623ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"str_pk\"] = df[\"float_pk\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "936348f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=[\"float_pk\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3e53ad53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 41078 entries, 0 to 41077\n",
      "Data columns (total 12 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   ride_id            41078 non-null  int64  \n",
      " 1   is_start           41078 non-null  int64  \n",
      " 2   pickup_datetime    41078 non-null  object \n",
      " 3   dropoff_datetime   41078 non-null  int64  \n",
      " 4   pickup_longitude   41078 non-null  float64\n",
      " 5   pickup_latitude    41078 non-null  float64\n",
      " 6   dropoff_longitude  41078 non-null  float64\n",
      " 7   dropoff_latitude   41078 non-null  float64\n",
      " 8   passenger_count    41078 non-null  int64  \n",
      " 9   taxi_id            41078 non-null  int64  \n",
      " 10  driver_id          41078 non-null  int64  \n",
      " 11  str_pk             41078 non-null  object \n",
      "dtypes: float64(4), int64(6), object(2)\n",
      "memory usage: 4.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "62f6d5da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching offline feature group backfill job...\n",
      "Backfill Job started successfully, you can follow the progress at https://hopsworks.glassfish.service.consul:8182/p/123/jobs/named/test2_str_fg_1_offline_fg_backfill/executions\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<hsfs.core.job.Job at 0x7f6cdf3a0ac0>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test2_str_fg = fs.create_feature_group(name=\"test2_str_fg\",\n",
    "                                   version=1,\n",
    "                                   primary_key=[\"str_pk\"],   \n",
    "                                   description=\"test2_str_fg\")   \n",
    "test2_str_fg.save(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8029faa4",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8df781ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=[\"str_pk\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e582c9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.is_start = df.is_start.astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a7674d68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 41078 entries, 0 to 41077\n",
      "Data columns (total 11 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   ride_id            41078 non-null  int64  \n",
      " 1   is_start           41078 non-null  bool   \n",
      " 2   pickup_datetime    41078 non-null  object \n",
      " 3   dropoff_datetime   41078 non-null  int64  \n",
      " 4   pickup_longitude   41078 non-null  float64\n",
      " 5   pickup_latitude    41078 non-null  float64\n",
      " 6   dropoff_longitude  41078 non-null  float64\n",
      " 7   dropoff_latitude   41078 non-null  float64\n",
      " 8   passenger_count    41078 non-null  int64  \n",
      " 9   taxi_id            41078 non-null  int64  \n",
      " 10  driver_id          41078 non-null  int64  \n",
      "dtypes: bool(1), float64(4), int64(5), object(1)\n",
      "memory usage: 3.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d58f74c5",
   "metadata": {},
   "outputs": [
    {
     "ename": "RestAPIError",
     "evalue": "Metadata operation error: (url: https://hopsworks.glassfish.service.consul:8182/hopsworks-api/api/project/123/featurestores/71/featuregroups). Server response: \nHTTP code: 500, HTTP reason: Internal Server Error, error code: 270001, error msg: Could not create feature group and corresponding Hive table, user msg: Error creating feature group table in the Hive Metastore: Invalid column type: bool",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRestAPIError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-dc0f93075c79>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m                                    \u001b[0mprimary_key\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"is_start\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                    description=\"test2_bool_fg\")   \n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtest2_bool_fg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/srv/hops/anaconda/envs/theenv/lib/python3.8/site-packages/hsfs/feature_group.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, features, write_options)\u001b[0m\n\u001b[1;32m    859\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m         \u001b[0;31m# fg_job is used only if the python engine is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 861\u001b[0;31m         \u001b[0mfg_job\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feature_group_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_dataframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrite_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    862\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_code_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatistics_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"spark\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/hops/anaconda/envs/theenv/lib/python3.8/site-packages/hsfs/core/feature_group_engine.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, feature_group, feature_dataframe, write_options)\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0mfeature_group\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_options\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrite_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feature_group_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_group\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m         \u001b[0mvalidation_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfeature_group\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidation_type\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"NONE\"\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"spark\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/hops/anaconda/envs/theenv/lib/python3.8/site-packages/hsfs/core/feature_group_api.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, feature_group_instance)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         return feature_group_instance.update_from_response_json(\n\u001b[0;32m---> 49\u001b[0;31m             _client._send_request(\n\u001b[0m\u001b[1;32m     50\u001b[0m                 \u001b[0;34m\"POST\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m                 \u001b[0mpath_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/hops/anaconda/envs/theenv/lib/python3.8/site-packages/hsfs/decorators.py\u001b[0m in \u001b[0;36mif_connected\u001b[0;34m(inst, *args, **kwargs)\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0minst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_connected\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mNoHopsworksConnectionError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mif_connected\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/hops/anaconda/envs/theenv/lib/python3.8/site-packages/hsfs/client/base.py\u001b[0m in \u001b[0;36m_send_request\u001b[0;34m(self, method, path_params, query_params, headers, data, stream, files)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRestAPIError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRestAPIError\u001b[0m: Metadata operation error: (url: https://hopsworks.glassfish.service.consul:8182/hopsworks-api/api/project/123/featurestores/71/featuregroups). Server response: \nHTTP code: 500, HTTP reason: Internal Server Error, error code: 270001, error msg: Could not create feature group and corresponding Hive table, user msg: Error creating feature group table in the Hive Metastore: Invalid column type: bool"
     ]
    }
   ],
   "source": [
    "test2_bool_fg = fs.create_feature_group(name=\"test2_bool_fg\",\n",
    "                                   version=1,\n",
    "                                   primary_key=[\"is_start\"],   \n",
    "                                   description=\"test2_bool_fg\")   \n",
    "test2_bool_fg.save(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cd41296a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.is_start = df.is_start.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6c255145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching offline feature group backfill job...\n",
      "Backfill Job started successfully, you can follow the progress at https://hopsworks.glassfish.service.consul:8182/p/123/jobs/named/test2_bool_fg_1_offline_fg_backfill/executions\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<hsfs.core.job.Job at 0x7f6cdf07eb80>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test2_bool_fg = fs.create_feature_group(name=\"test2_bool_fg\",\n",
    "                                   version=1,\n",
    "                                   primary_key=[\"is_start\"],   \n",
    "                                   description=\"test2_bool_fg\")   \n",
    "test2_bool_fg.save(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0586cd4a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8b924e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"datetime\"] = pd.to_datetime(df[\"pickup_datetime\"], unit='ms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4c658ff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 41078 entries, 0 to 41077\n",
      "Data columns (total 12 columns):\n",
      " #   Column             Non-Null Count  Dtype         \n",
      "---  ------             --------------  -----         \n",
      " 0   ride_id            41078 non-null  int64         \n",
      " 1   is_start           41078 non-null  int64         \n",
      " 2   pickup_datetime    41078 non-null  object        \n",
      " 3   dropoff_datetime   41078 non-null  int64         \n",
      " 4   pickup_longitude   41078 non-null  float64       \n",
      " 5   pickup_latitude    41078 non-null  float64       \n",
      " 6   dropoff_longitude  41078 non-null  float64       \n",
      " 7   dropoff_latitude   41078 non-null  float64       \n",
      " 8   passenger_count    41078 non-null  int64         \n",
      " 9   taxi_id            41078 non-null  int64         \n",
      " 10  driver_id          41078 non-null  int64         \n",
      " 11  datetime           41078 non-null  datetime64[ns]\n",
      "dtypes: datetime64[ns](1), float64(4), int64(6), object(1)\n",
      "memory usage: 4.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "69faf711",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching offline feature group backfill job...\n",
      "Backfill Job started successfully, you can follow the progress at https://hopsworks.glassfish.service.consul:8182/p/123/jobs/named/test2_datetime_fg_1_offline_fg_backfill/executions\n"
     ]
    },
    {
     "ename": "FeatureStoreException",
     "evalue": "The Hopsworks Job failed, use the Hopsworks UI to access the job logs",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFeatureStoreException\u001b[0m                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-e9f1f0ed1470>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m                                    \u001b[0mprimary_key\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"datetime\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                    description=\"test2_datetime_fg\")   \n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtest2_datetime_fg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/srv/hops/anaconda/envs/theenv/lib/python3.8/site-packages/hsfs/feature_group.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, features, write_options)\u001b[0m\n\u001b[1;32m    859\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m         \u001b[0;31m# fg_job is used only if the python engine is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 861\u001b[0;31m         \u001b[0mfg_job\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feature_group_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_dataframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrite_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    862\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_code_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatistics_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"spark\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/hops/anaconda/envs/theenv/lib/python3.8/site-packages/hsfs/core/feature_group_engine.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, feature_group, feature_dataframe, write_options)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0monline_write_options\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_kafka_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrite_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         return engine.get_instance().save_dataframe(\n\u001b[0m\u001b[1;32m     66\u001b[0m             \u001b[0mfeature_group\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfeature_dataframe\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/hops/anaconda/envs/theenv/lib/python3.8/site-packages/hsfs/engine/python.py\u001b[0m in \u001b[0;36msave_dataframe\u001b[0;34m(self, feature_group, dataframe, operation, online_enabled, storage, offline_write_options, online_write_options, validation_id)\u001b[0m\n\u001b[1;32m    372\u001b[0m     ):\n\u001b[1;32m    373\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfeature_group\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 374\u001b[0;31m             return self._write_dataframe_kafka(\n\u001b[0m\u001b[1;32m    375\u001b[0m                 \u001b[0mfeature_group\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffline_write_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m             )\n",
      "\u001b[0;32m/srv/hops/anaconda/envs/theenv/lib/python3.8/site-packages/hsfs/engine/python.py\u001b[0m in \u001b[0;36m_write_dataframe_kafka\u001b[0;34m(self, feature_group, dataframe, offline_write_options)\u001b[0m\n\u001b[1;32m    728\u001b[0m                 )\n\u001b[1;32m    729\u001b[0m             )\n\u001b[0;32m--> 730\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_for_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffline_write_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    731\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    732\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mjob\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/hops/anaconda/envs/theenv/lib/python3.8/site-packages/hsfs/engine/python.py\u001b[0m in \u001b[0;36m_wait_for_job\u001b[0;34m(self, job, user_write_options)\u001b[0m\n\u001b[1;32m    624\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mexecution\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinal_status\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"failed\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 626\u001b[0;31m                 raise exceptions.FeatureStoreException(\n\u001b[0m\u001b[1;32m    627\u001b[0m                     \u001b[0;34m\"The Hopsworks Job failed, use the Hopsworks UI to access the job logs\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m                 )\n",
      "\u001b[0;31mFeatureStoreException\u001b[0m: The Hopsworks Job failed, use the Hopsworks UI to access the job logs"
     ]
    }
   ],
   "source": [
    "test2_datetime_fg = fs.create_feature_group(name=\"test2_datetime_fg\",\n",
    "                                   version=1,\n",
    "                                   primary_key=[\"datetime\"],   \n",
    "                                   description=\"test2_datetime_fg\")   \n",
    "test2_datetime_fg.save(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "614b5ce2",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ebde7e",
   "metadata": {},
   "source": [
    "## 3) Create feature group with ordinary datetime columns (not PK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8d803d7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2020-01-01 18:49:20')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.datetime[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d54c7bea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching offline feature group backfill job...\n",
      "Backfill Job started successfully, you can follow the progress at https://hopsworks.glassfish.service.consul:8182/p/123/jobs/named/test3_fg_1_offline_fg_backfill/executions\n"
     ]
    },
    {
     "ename": "FeatureStoreException",
     "evalue": "The Hopsworks Job failed, use the Hopsworks UI to access the job logs",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFeatureStoreException\u001b[0m                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-61-82c0e01a26de>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m                                    \u001b[0mprimary_key\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ride_id\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                    description=\"test3_fg\")   \n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtest3_fg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/srv/hops/anaconda/envs/theenv/lib/python3.8/site-packages/hsfs/feature_group.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, features, write_options)\u001b[0m\n\u001b[1;32m    859\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m         \u001b[0;31m# fg_job is used only if the python engine is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 861\u001b[0;31m         \u001b[0mfg_job\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feature_group_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_dataframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrite_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    862\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_code_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatistics_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"spark\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/hops/anaconda/envs/theenv/lib/python3.8/site-packages/hsfs/core/feature_group_engine.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, feature_group, feature_dataframe, write_options)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0monline_write_options\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_kafka_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrite_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         return engine.get_instance().save_dataframe(\n\u001b[0m\u001b[1;32m     66\u001b[0m             \u001b[0mfeature_group\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfeature_dataframe\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/hops/anaconda/envs/theenv/lib/python3.8/site-packages/hsfs/engine/python.py\u001b[0m in \u001b[0;36msave_dataframe\u001b[0;34m(self, feature_group, dataframe, operation, online_enabled, storage, offline_write_options, online_write_options, validation_id)\u001b[0m\n\u001b[1;32m    372\u001b[0m     ):\n\u001b[1;32m    373\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfeature_group\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 374\u001b[0;31m             return self._write_dataframe_kafka(\n\u001b[0m\u001b[1;32m    375\u001b[0m                 \u001b[0mfeature_group\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffline_write_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m             )\n",
      "\u001b[0;32m/srv/hops/anaconda/envs/theenv/lib/python3.8/site-packages/hsfs/engine/python.py\u001b[0m in \u001b[0;36m_write_dataframe_kafka\u001b[0;34m(self, feature_group, dataframe, offline_write_options)\u001b[0m\n\u001b[1;32m    728\u001b[0m                 )\n\u001b[1;32m    729\u001b[0m             )\n\u001b[0;32m--> 730\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_for_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffline_write_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    731\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    732\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mjob\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/hops/anaconda/envs/theenv/lib/python3.8/site-packages/hsfs/engine/python.py\u001b[0m in \u001b[0;36m_wait_for_job\u001b[0;34m(self, job, user_write_options)\u001b[0m\n\u001b[1;32m    624\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mexecution\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinal_status\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"failed\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 626\u001b[0;31m                 raise exceptions.FeatureStoreException(\n\u001b[0m\u001b[1;32m    627\u001b[0m                     \u001b[0;34m\"The Hopsworks Job failed, use the Hopsworks UI to access the job logs\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m                 )\n",
      "\u001b[0;31mFeatureStoreException\u001b[0m: The Hopsworks Job failed, use the Hopsworks UI to access the job logs"
     ]
    }
   ],
   "source": [
    "test3_fg = fs.create_feature_group(name=\"test3_fg\",\n",
    "                                   version=1,\n",
    "                                   primary_key=[\"ride_id\"],   \n",
    "                                   description=\"test3_fg\")   \n",
    "test3_fg.save(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c8e70b",
   "metadata": {},
   "source": [
    "## 4) Create feature group with duplicated PK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7071db44",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=[\"datetime\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e335a8ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ride_id</th>\n",
       "      <th>is_start</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>dropoff_datetime</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>taxi_id</th>\n",
       "      <th>driver_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1228</td>\n",
       "      <td>1</td>\n",
       "      <td>1577904560000</td>\n",
       "      <td>0</td>\n",
       "      <td>-73.867676</td>\n",
       "      <td>40.759323</td>\n",
       "      <td>-73.864080</td>\n",
       "      <td>40.763897</td>\n",
       "      <td>3</td>\n",
       "      <td>2013000194</td>\n",
       "      <td>2013000194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>527</td>\n",
       "      <td>1</td>\n",
       "      <td>1577890540000</td>\n",
       "      <td>0</td>\n",
       "      <td>-73.857086</td>\n",
       "      <td>40.772793</td>\n",
       "      <td>-73.807335</td>\n",
       "      <td>40.836117</td>\n",
       "      <td>3</td>\n",
       "      <td>2013000122</td>\n",
       "      <td>2013000122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>394</td>\n",
       "      <td>1</td>\n",
       "      <td>1577887880000</td>\n",
       "      <td>0</td>\n",
       "      <td>-73.844320</td>\n",
       "      <td>40.789043</td>\n",
       "      <td>-73.765950</td>\n",
       "      <td>40.888790</td>\n",
       "      <td>3</td>\n",
       "      <td>2013000102</td>\n",
       "      <td>2013000102</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ride_id  is_start pickup_datetime  dropoff_datetime  pickup_longitude  \\\n",
       "0     1228         1   1577904560000                 0        -73.867676   \n",
       "1      527         1   1577890540000                 0        -73.857086   \n",
       "2      394         1   1577887880000                 0        -73.844320   \n",
       "\n",
       "   pickup_latitude  dropoff_longitude  dropoff_latitude  passenger_count  \\\n",
       "0        40.759323         -73.864080         40.763897                3   \n",
       "1        40.772793         -73.807335         40.836117                3   \n",
       "2        40.789043         -73.765950         40.888790                3   \n",
       "\n",
       "      taxi_id   driver_id  \n",
       "0  2013000194  2013000194  \n",
       "1  2013000122  2013000122  \n",
       "2  2013000102  2013000102  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0b4c5277",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.taxi_id.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "687a3a5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching offline feature group backfill job...\n",
      "Backfill Job started successfully, you can follow the progress at https://hopsworks.glassfish.service.consul:8182/p/123/jobs/named/test4_fg_1_offline_fg_backfill/executions\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<hsfs.core.job.Job at 0x7f6cdff63520>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test4_fg = fs.create_feature_group(name=\"test4_fg\",\n",
    "                                   version=1,\n",
    "                                   primary_key=[\"taxi_id\"],   \n",
    "                                   description=\"test4_fg\")   \n",
    "test4_fg.save(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3cbb4fc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected. Call `.close()` to terminate connection gracefully.\n"
     ]
    }
   ],
   "source": [
    "import hsfs\n",
    "connection = hsfs.connection()\n",
    "fs = connection.get_feature_store(name='testing_featurestore')\n",
    "fg = fs.get_feature_group('test4_fg', version=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "811f86f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-25 23:01:07,518 INFO: USE `testing_featurestore`\n",
      "2022-05-25 23:01:08,515 INFO: SELECT `fg0`.`ride_id` `ride_id`, `fg0`.`is_start` `is_start`, `fg0`.`pickup_datetime` `pickup_datetime`, `fg0`.`dropoff_datetime` `dropoff_datetime`, `fg0`.`pickup_longitude` `pickup_longitude`, `fg0`.`pickup_latitude` `pickup_latitude`, `fg0`.`dropoff_longitude` `dropoff_longitude`, `fg0`.`dropoff_latitude` `dropoff_latitude`, `fg0`.`passenger_count` `passenger_count`, `fg0`.`taxi_id` `taxi_id`, `fg0`.`driver_id` `driver_id`\n",
      "FROM `testing_featurestore`.`test4_fg_1` `fg0`\n"
     ]
    }
   ],
   "source": [
    "df_from_fg = fg.read(dataframe_type=\"pandas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "47e35e2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 11)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_from_fg.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d58bbba",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88fffa0d",
   "metadata": {},
   "source": [
    "## 5) Create even time enabled feature group "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2899dc33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 41078 entries, 0 to 41077\n",
      "Data columns (total 11 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   ride_id            41078 non-null  int64  \n",
      " 1   is_start           41078 non-null  bool   \n",
      " 2   pickup_datetime    41078 non-null  object \n",
      " 3   dropoff_datetime   41078 non-null  int64  \n",
      " 4   pickup_longitude   41078 non-null  float64\n",
      " 5   pickup_latitude    41078 non-null  float64\n",
      " 6   dropoff_longitude  41078 non-null  float64\n",
      " 7   dropoff_latitude   41078 non-null  float64\n",
      " 8   passenger_count    41078 non-null  int64  \n",
      " 9   taxi_id            41078 non-null  int64  \n",
      " 10  driver_id          41078 non-null  int64  \n",
      "dtypes: bool(1), float64(4), int64(5), object(1)\n",
      "memory usage: 3.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bdfce20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=[\"is_start\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cb55e903",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.pickup_datetime = df.pickup_datetime.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1d020ff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching offline feature group backfill job...\n",
      "Backfill Job started successfully, you can follow the progress at https://hopsworks.glassfish.service.consul:8182/p/123/jobs/named/test5_fg_1_offline_fg_backfill/executions\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<hsfs.core.job.Job at 0x7f9be748d7c0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test5_fg = fs.create_feature_group(name=\"test5_fg\",\n",
    "                                   version=1,\n",
    "                                   primary_key=[\"ride_id\"],   \n",
    "                                   description=\"test5_fg\",\n",
    "                                   event_time=[\"pickup_datetime\"])   \n",
    "test5_fg.save(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b3b94d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e15ad0",
   "metadata": {},
   "source": [
    "## 6) Create fg with partition_key of specific type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e43ad2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"hdfs:///Projects/{}/Resources/rides.csv\".format(hdfs.project_name()), index_col=0,\n",
    "                       parse_dates=[\"pickup_datetime\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "42246f1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 41078 entries, 0 to 41077\n",
      "Data columns (total 11 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   ride_id            41078 non-null  int64  \n",
      " 1   is_start           41078 non-null  bool   \n",
      " 2   pickup_datetime    41078 non-null  object \n",
      " 3   dropoff_datetime   41078 non-null  int64  \n",
      " 4   pickup_longitude   41078 non-null  float64\n",
      " 5   pickup_latitude    41078 non-null  float64\n",
      " 6   dropoff_longitude  41078 non-null  float64\n",
      " 7   dropoff_latitude   41078 non-null  float64\n",
      " 8   passenger_count    41078 non-null  int64  \n",
      " 9   taxi_id            41078 non-null  int64  \n",
      " 10  driver_id          41078 non-null  int64  \n",
      "dtypes: bool(1), float64(4), int64(5), object(1)\n",
      "memory usage: 3.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1e854779",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=[\"is_start\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8f07d29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropoff_datetime = df.dropoff_datetime.astype(np.byte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "de8db069",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 41078 entries, 0 to 41077\n",
      "Data columns (total 10 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   ride_id            41078 non-null  int64  \n",
      " 1   pickup_datetime    41078 non-null  object \n",
      " 2   dropoff_datetime   41078 non-null  int8   \n",
      " 3   pickup_longitude   41078 non-null  float64\n",
      " 4   pickup_latitude    41078 non-null  float64\n",
      " 5   dropoff_longitude  41078 non-null  float64\n",
      " 6   dropoff_latitude   41078 non-null  float64\n",
      " 7   passenger_count    41078 non-null  int64  \n",
      " 8   taxi_id            41078 non-null  int64  \n",
      " 9   driver_id          41078 non-null  int64  \n",
      "dtypes: float64(4), int64(4), int8(1), object(1)\n",
      "memory usage: 3.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4afabe20",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "0 (type <class 'int'>) do not match ['null', 'string'] on field dropoff_datetime",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-0337dbf84aee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m                                    \u001b[0mprimary_key\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ride_id\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                    description=\"test6_byte_fg\")   \n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtest6_byte_fg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/srv/hops/anaconda/envs/theenv/lib/python3.8/site-packages/hsfs/feature_group.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, features, write_options)\u001b[0m\n\u001b[1;32m    859\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m         \u001b[0;31m# fg_job is used only if the python engine is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 861\u001b[0;31m         \u001b[0mfg_job\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feature_group_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_dataframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrite_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    862\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_code_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatistics_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"spark\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/hops/anaconda/envs/theenv/lib/python3.8/site-packages/hsfs/core/feature_group_engine.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, feature_group, feature_dataframe, write_options)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0monline_write_options\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_kafka_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrite_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         return engine.get_instance().save_dataframe(\n\u001b[0m\u001b[1;32m     66\u001b[0m             \u001b[0mfeature_group\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfeature_dataframe\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/hops/anaconda/envs/theenv/lib/python3.8/site-packages/hsfs/engine/python.py\u001b[0m in \u001b[0;36msave_dataframe\u001b[0;34m(self, feature_group, dataframe, operation, online_enabled, storage, offline_write_options, online_write_options, validation_id)\u001b[0m\n\u001b[1;32m    372\u001b[0m     ):\n\u001b[1;32m    373\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfeature_group\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 374\u001b[0;31m             return self._write_dataframe_kafka(\n\u001b[0m\u001b[1;32m    375\u001b[0m                 \u001b[0mfeature_group\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffline_write_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m             )\n",
      "\u001b[0;32m/srv/hops/anaconda/envs/theenv/lib/python3.8/site-packages/hsfs/engine/python.py\u001b[0m in \u001b[0;36m_write_dataframe_kafka\u001b[0;34m(self, feature_group, dataframe, offline_write_options)\u001b[0m\n\u001b[1;32m    695\u001b[0m             \u001b[0;31m# encode feature row\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    696\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0moutf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 697\u001b[0;31m                 \u001b[0mwriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    698\u001b[0m                 \u001b[0mencoded_row\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/hops/anaconda/envs/theenv/lib/python3.8/site-packages/hsfs/engine/python.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(record, outf)\u001b[0m\n\u001b[1;32m    745\u001b[0m             \u001b[0mschema\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwriter_schema\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m             \u001b[0mparsed_schema\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_schema\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mschemaless_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparsed_schema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m         \u001b[0mparsed_schema\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mavro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwriter_schema\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mfastavro/_write.pyx\u001b[0m in \u001b[0;36mfastavro._write.schemaless_writer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mfastavro/_write.pyx\u001b[0m in \u001b[0;36mfastavro._write.write_data\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mfastavro/_write.pyx\u001b[0m in \u001b[0;36mfastavro._write.write_record\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mfastavro/_write.pyx\u001b[0m in \u001b[0;36mfastavro._write.write_data\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mfastavro/_write.pyx\u001b[0m in \u001b[0;36mfastavro._write.write_union\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: 0 (type <class 'int'>) do not match ['null', 'string'] on field dropoff_datetime"
     ]
    }
   ],
   "source": [
    "test6_byte_fg = fs.create_feature_group(name=\"test6_byte_fg\",\n",
    "                                   version=1,\n",
    "                                   primary_key=[\"ride_id\"],   \n",
    "                                   description=\"test6_byte_fg\")   \n",
    "test6_byte_fg.save(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "80d5e19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"hdfs:///Projects/{}/Resources/rides.csv\".format(hdfs.project_name()), index_col=0,\n",
    "                       parse_dates=[\"pickup_datetime\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7d0c573e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.is_start = df.is_start.astype(np.ubyte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4dc4ac35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 41078 entries, 0 to 41077\n",
      "Data columns (total 11 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   ride_id            41078 non-null  int64  \n",
      " 1   is_start           41078 non-null  uint8  \n",
      " 2   pickup_datetime    41078 non-null  object \n",
      " 3   dropoff_datetime   41078 non-null  int64  \n",
      " 4   pickup_longitude   41078 non-null  float64\n",
      " 5   pickup_latitude    41078 non-null  float64\n",
      " 6   dropoff_longitude  41078 non-null  float64\n",
      " 7   dropoff_latitude   41078 non-null  float64\n",
      " 8   passenger_count    41078 non-null  int64  \n",
      " 9   taxi_id            41078 non-null  int64  \n",
      " 10  driver_id          41078 non-null  int64  \n",
      "dtypes: float64(4), int64(5), object(1), uint8(1)\n",
      "memory usage: 3.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2efe1326",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "1 (type <class 'int'>) do not match ['null', 'string'] on field is_start",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-c9daafedd09a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m                                    \u001b[0mprimary_key\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ride_id\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                    description=\"test6_ubyte_fg\")   \n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtest6_ubyte_fg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/srv/hops/anaconda/envs/theenv/lib/python3.8/site-packages/hsfs/feature_group.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, features, write_options)\u001b[0m\n\u001b[1;32m    859\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m         \u001b[0;31m# fg_job is used only if the python engine is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 861\u001b[0;31m         \u001b[0mfg_job\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feature_group_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_dataframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrite_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    862\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_code_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatistics_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"spark\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/hops/anaconda/envs/theenv/lib/python3.8/site-packages/hsfs/core/feature_group_engine.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, feature_group, feature_dataframe, write_options)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0monline_write_options\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_kafka_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrite_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         return engine.get_instance().save_dataframe(\n\u001b[0m\u001b[1;32m     66\u001b[0m             \u001b[0mfeature_group\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfeature_dataframe\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/hops/anaconda/envs/theenv/lib/python3.8/site-packages/hsfs/engine/python.py\u001b[0m in \u001b[0;36msave_dataframe\u001b[0;34m(self, feature_group, dataframe, operation, online_enabled, storage, offline_write_options, online_write_options, validation_id)\u001b[0m\n\u001b[1;32m    372\u001b[0m     ):\n\u001b[1;32m    373\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfeature_group\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 374\u001b[0;31m             return self._write_dataframe_kafka(\n\u001b[0m\u001b[1;32m    375\u001b[0m                 \u001b[0mfeature_group\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffline_write_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m             )\n",
      "\u001b[0;32m/srv/hops/anaconda/envs/theenv/lib/python3.8/site-packages/hsfs/engine/python.py\u001b[0m in \u001b[0;36m_write_dataframe_kafka\u001b[0;34m(self, feature_group, dataframe, offline_write_options)\u001b[0m\n\u001b[1;32m    695\u001b[0m             \u001b[0;31m# encode feature row\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    696\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0moutf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 697\u001b[0;31m                 \u001b[0mwriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    698\u001b[0m                 \u001b[0mencoded_row\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/hops/anaconda/envs/theenv/lib/python3.8/site-packages/hsfs/engine/python.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(record, outf)\u001b[0m\n\u001b[1;32m    745\u001b[0m             \u001b[0mschema\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwriter_schema\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m             \u001b[0mparsed_schema\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_schema\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mschemaless_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparsed_schema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m         \u001b[0mparsed_schema\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mavro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwriter_schema\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mfastavro/_write.pyx\u001b[0m in \u001b[0;36mfastavro._write.schemaless_writer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mfastavro/_write.pyx\u001b[0m in \u001b[0;36mfastavro._write.write_data\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mfastavro/_write.pyx\u001b[0m in \u001b[0;36mfastavro._write.write_record\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mfastavro/_write.pyx\u001b[0m in \u001b[0;36mfastavro._write.write_data\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mfastavro/_write.pyx\u001b[0m in \u001b[0;36mfastavro._write.write_union\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: 1 (type <class 'int'>) do not match ['null', 'string'] on field is_start"
     ]
    }
   ],
   "source": [
    "test6_ubyte_fg = fs.create_feature_group(name=\"test6_ubyte_fg\",\n",
    "                                   version=1,\n",
    "                                   primary_key=[\"ride_id\"],   \n",
    "                                   description=\"test6_ubyte_fg\")   \n",
    "test6_ubyte_fg.save(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "31a8d191",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.is_start = df.is_start.astype(np.short)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d11a2cfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 41078 entries, 0 to 41077\n",
      "Data columns (total 11 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   ride_id            41078 non-null  int64  \n",
      " 1   is_start           41078 non-null  int16  \n",
      " 2   pickup_datetime    41078 non-null  object \n",
      " 3   dropoff_datetime   41078 non-null  int64  \n",
      " 4   pickup_longitude   41078 non-null  float64\n",
      " 5   pickup_latitude    41078 non-null  float64\n",
      " 6   dropoff_longitude  41078 non-null  float64\n",
      " 7   dropoff_latitude   41078 non-null  float64\n",
      " 8   passenger_count    41078 non-null  int64  \n",
      " 9   taxi_id            41078 non-null  int64  \n",
      " 10  driver_id          41078 non-null  int64  \n",
      "dtypes: float64(4), int16(1), int64(5), object(1)\n",
      "memory usage: 3.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e3a2db91",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "1 (type <class 'int'>) do not match ['null', 'string'] on field is_start",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-ac7e67873431>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m                                    \u001b[0mprimary_key\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ride_id\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                    description=\"test6_short_fg\")   \n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtest6_short_fg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/srv/hops/anaconda/envs/theenv/lib/python3.8/site-packages/hsfs/feature_group.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, features, write_options)\u001b[0m\n\u001b[1;32m    859\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m         \u001b[0;31m# fg_job is used only if the python engine is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 861\u001b[0;31m         \u001b[0mfg_job\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feature_group_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_dataframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrite_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    862\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_code_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatistics_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"spark\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/hops/anaconda/envs/theenv/lib/python3.8/site-packages/hsfs/core/feature_group_engine.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, feature_group, feature_dataframe, write_options)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0monline_write_options\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_kafka_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrite_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         return engine.get_instance().save_dataframe(\n\u001b[0m\u001b[1;32m     66\u001b[0m             \u001b[0mfeature_group\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfeature_dataframe\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/hops/anaconda/envs/theenv/lib/python3.8/site-packages/hsfs/engine/python.py\u001b[0m in \u001b[0;36msave_dataframe\u001b[0;34m(self, feature_group, dataframe, operation, online_enabled, storage, offline_write_options, online_write_options, validation_id)\u001b[0m\n\u001b[1;32m    372\u001b[0m     ):\n\u001b[1;32m    373\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfeature_group\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 374\u001b[0;31m             return self._write_dataframe_kafka(\n\u001b[0m\u001b[1;32m    375\u001b[0m                 \u001b[0mfeature_group\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffline_write_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m             )\n",
      "\u001b[0;32m/srv/hops/anaconda/envs/theenv/lib/python3.8/site-packages/hsfs/engine/python.py\u001b[0m in \u001b[0;36m_write_dataframe_kafka\u001b[0;34m(self, feature_group, dataframe, offline_write_options)\u001b[0m\n\u001b[1;32m    695\u001b[0m             \u001b[0;31m# encode feature row\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    696\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0moutf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 697\u001b[0;31m                 \u001b[0mwriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    698\u001b[0m                 \u001b[0mencoded_row\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/hops/anaconda/envs/theenv/lib/python3.8/site-packages/hsfs/engine/python.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(record, outf)\u001b[0m\n\u001b[1;32m    745\u001b[0m             \u001b[0mschema\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwriter_schema\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m             \u001b[0mparsed_schema\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_schema\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mschemaless_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparsed_schema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m         \u001b[0mparsed_schema\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mavro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwriter_schema\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mfastavro/_write.pyx\u001b[0m in \u001b[0;36mfastavro._write.schemaless_writer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mfastavro/_write.pyx\u001b[0m in \u001b[0;36mfastavro._write.write_data\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mfastavro/_write.pyx\u001b[0m in \u001b[0;36mfastavro._write.write_record\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mfastavro/_write.pyx\u001b[0m in \u001b[0;36mfastavro._write.write_data\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mfastavro/_write.pyx\u001b[0m in \u001b[0;36mfastavro._write.write_union\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: 1 (type <class 'int'>) do not match ['null', 'string'] on field is_start"
     ]
    }
   ],
   "source": [
    "test6_short_fg = fs.create_feature_group(name=\"test6_short_fg\",\n",
    "                                   version=1,\n",
    "                                   primary_key=[\"ride_id\"],   \n",
    "                                   description=\"test6_short_fg\")   \n",
    "test6_short_fg.save(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "806c91bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.is_start = df.is_start.astype(np.ushort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1b4075e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 41078 entries, 0 to 41077\n",
      "Data columns (total 11 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   ride_id            41078 non-null  int64  \n",
      " 1   is_start           41078 non-null  uint16 \n",
      " 2   pickup_datetime    41078 non-null  object \n",
      " 3   dropoff_datetime   41078 non-null  int64  \n",
      " 4   pickup_longitude   41078 non-null  float64\n",
      " 5   pickup_latitude    41078 non-null  float64\n",
      " 6   dropoff_longitude  41078 non-null  float64\n",
      " 7   dropoff_latitude   41078 non-null  float64\n",
      " 8   passenger_count    41078 non-null  int64  \n",
      " 9   taxi_id            41078 non-null  int64  \n",
      " 10  driver_id          41078 non-null  int64  \n",
      "dtypes: float64(4), int64(5), object(1), uint16(1)\n",
      "memory usage: 3.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "24b82277",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "1 (type <class 'int'>) do not match ['null', 'string'] on field is_start",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-4cccdf8bbf22>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m                                    \u001b[0mprimary_key\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ride_id\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                    description=\"test6_ushort_fg\")   \n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtest6_ushort_fg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/srv/hops/anaconda/envs/theenv/lib/python3.8/site-packages/hsfs/feature_group.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, features, write_options)\u001b[0m\n\u001b[1;32m    859\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m         \u001b[0;31m# fg_job is used only if the python engine is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 861\u001b[0;31m         \u001b[0mfg_job\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feature_group_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_dataframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrite_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    862\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_code_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatistics_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"spark\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/hops/anaconda/envs/theenv/lib/python3.8/site-packages/hsfs/core/feature_group_engine.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, feature_group, feature_dataframe, write_options)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0monline_write_options\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_kafka_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrite_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         return engine.get_instance().save_dataframe(\n\u001b[0m\u001b[1;32m     66\u001b[0m             \u001b[0mfeature_group\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfeature_dataframe\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/hops/anaconda/envs/theenv/lib/python3.8/site-packages/hsfs/engine/python.py\u001b[0m in \u001b[0;36msave_dataframe\u001b[0;34m(self, feature_group, dataframe, operation, online_enabled, storage, offline_write_options, online_write_options, validation_id)\u001b[0m\n\u001b[1;32m    372\u001b[0m     ):\n\u001b[1;32m    373\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfeature_group\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 374\u001b[0;31m             return self._write_dataframe_kafka(\n\u001b[0m\u001b[1;32m    375\u001b[0m                 \u001b[0mfeature_group\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffline_write_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m             )\n",
      "\u001b[0;32m/srv/hops/anaconda/envs/theenv/lib/python3.8/site-packages/hsfs/engine/python.py\u001b[0m in \u001b[0;36m_write_dataframe_kafka\u001b[0;34m(self, feature_group, dataframe, offline_write_options)\u001b[0m\n\u001b[1;32m    695\u001b[0m             \u001b[0;31m# encode feature row\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    696\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0moutf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 697\u001b[0;31m                 \u001b[0mwriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    698\u001b[0m                 \u001b[0mencoded_row\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/hops/anaconda/envs/theenv/lib/python3.8/site-packages/hsfs/engine/python.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(record, outf)\u001b[0m\n\u001b[1;32m    745\u001b[0m             \u001b[0mschema\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwriter_schema\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m             \u001b[0mparsed_schema\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_schema\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mschemaless_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparsed_schema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m         \u001b[0mparsed_schema\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mavro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwriter_schema\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mfastavro/_write.pyx\u001b[0m in \u001b[0;36mfastavro._write.schemaless_writer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mfastavro/_write.pyx\u001b[0m in \u001b[0;36mfastavro._write.write_data\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mfastavro/_write.pyx\u001b[0m in \u001b[0;36mfastavro._write.write_record\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mfastavro/_write.pyx\u001b[0m in \u001b[0;36mfastavro._write.write_data\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mfastavro/_write.pyx\u001b[0m in \u001b[0;36mfastavro._write.write_union\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: 1 (type <class 'int'>) do not match ['null', 'string'] on field is_start"
     ]
    }
   ],
   "source": [
    "test6_ushort_fg = fs.create_feature_group(name=\"test6_ushort_fg\",\n",
    "                                   version=1,\n",
    "                                   primary_key=[\"ride_id\"],   \n",
    "                                   description=\"test6_ushort_fg\")   \n",
    "test6_ushort_fg.save(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fb2db6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.is_start = df.is_start.astype(np.intc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1b3324ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 41078 entries, 0 to 41077\n",
      "Data columns (total 11 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   ride_id            41078 non-null  int64  \n",
      " 1   is_start           41078 non-null  int32  \n",
      " 2   pickup_datetime    41078 non-null  object \n",
      " 3   dropoff_datetime   41078 non-null  int64  \n",
      " 4   pickup_longitude   41078 non-null  float64\n",
      " 5   pickup_latitude    41078 non-null  float64\n",
      " 6   dropoff_longitude  41078 non-null  float64\n",
      " 7   dropoff_latitude   41078 non-null  float64\n",
      " 8   passenger_count    41078 non-null  int64  \n",
      " 9   taxi_id            41078 non-null  int64  \n",
      " 10  driver_id          41078 non-null  int64  \n",
      "dtypes: float64(4), int32(1), int64(5), object(1)\n",
      "memory usage: 3.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c298df36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching offline feature group backfill job...\n",
      "Backfill Job started successfully, you can follow the progress at https://hopsworks.glassfish.service.consul:8182/p/123/jobs/named/test6_intc_fg_1_offline_fg_backfill/executions\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<hsfs.core.job.Job at 0x7f9be6c5c940>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test6_intc_fg = fs.create_feature_group(name=\"test6_intc_fg\",\n",
    "                                   version=1,\n",
    "                                   primary_key=[\"ride_id\"],   \n",
    "                                   description=\"test6_intc_fg\")   \n",
    "test6_intc_fg.save(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2ae3b041",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.is_start = df.is_start.astype(np.uintc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ff2b44b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 41078 entries, 0 to 41077\n",
      "Data columns (total 11 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   ride_id            41078 non-null  int64  \n",
      " 1   is_start           41078 non-null  uint32 \n",
      " 2   pickup_datetime    41078 non-null  object \n",
      " 3   dropoff_datetime   41078 non-null  int64  \n",
      " 4   pickup_longitude   41078 non-null  float64\n",
      " 5   pickup_latitude    41078 non-null  float64\n",
      " 6   dropoff_longitude  41078 non-null  float64\n",
      " 7   dropoff_latitude   41078 non-null  float64\n",
      " 8   passenger_count    41078 non-null  int64  \n",
      " 9   taxi_id            41078 non-null  int64  \n",
      " 10  driver_id          41078 non-null  int64  \n",
      "dtypes: float64(4), int64(5), object(1), uint32(1)\n",
      "memory usage: 3.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f5b92329",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "1 (type <class 'int'>) do not match ['null', 'string'] on field is_start",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-3885aa07f5f8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m                                    \u001b[0mprimary_key\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ride_id\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                    description=\"test6_uintc_fg\")   \n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtest6_uintc_fg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/srv/hops/anaconda/envs/theenv/lib/python3.8/site-packages/hsfs/feature_group.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, features, write_options)\u001b[0m\n\u001b[1;32m    859\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m         \u001b[0;31m# fg_job is used only if the python engine is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 861\u001b[0;31m         \u001b[0mfg_job\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feature_group_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_dataframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrite_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    862\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_code_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatistics_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"spark\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/hops/anaconda/envs/theenv/lib/python3.8/site-packages/hsfs/core/feature_group_engine.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, feature_group, feature_dataframe, write_options)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0monline_write_options\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_kafka_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrite_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         return engine.get_instance().save_dataframe(\n\u001b[0m\u001b[1;32m     66\u001b[0m             \u001b[0mfeature_group\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfeature_dataframe\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/hops/anaconda/envs/theenv/lib/python3.8/site-packages/hsfs/engine/python.py\u001b[0m in \u001b[0;36msave_dataframe\u001b[0;34m(self, feature_group, dataframe, operation, online_enabled, storage, offline_write_options, online_write_options, validation_id)\u001b[0m\n\u001b[1;32m    372\u001b[0m     ):\n\u001b[1;32m    373\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfeature_group\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 374\u001b[0;31m             return self._write_dataframe_kafka(\n\u001b[0m\u001b[1;32m    375\u001b[0m                 \u001b[0mfeature_group\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffline_write_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m             )\n",
      "\u001b[0;32m/srv/hops/anaconda/envs/theenv/lib/python3.8/site-packages/hsfs/engine/python.py\u001b[0m in \u001b[0;36m_write_dataframe_kafka\u001b[0;34m(self, feature_group, dataframe, offline_write_options)\u001b[0m\n\u001b[1;32m    695\u001b[0m             \u001b[0;31m# encode feature row\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    696\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0moutf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 697\u001b[0;31m                 \u001b[0mwriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    698\u001b[0m                 \u001b[0mencoded_row\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/hops/anaconda/envs/theenv/lib/python3.8/site-packages/hsfs/engine/python.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(record, outf)\u001b[0m\n\u001b[1;32m    745\u001b[0m             \u001b[0mschema\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwriter_schema\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m             \u001b[0mparsed_schema\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_schema\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mschemaless_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparsed_schema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m         \u001b[0mparsed_schema\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mavro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwriter_schema\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mfastavro/_write.pyx\u001b[0m in \u001b[0;36mfastavro._write.schemaless_writer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mfastavro/_write.pyx\u001b[0m in \u001b[0;36mfastavro._write.write_data\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mfastavro/_write.pyx\u001b[0m in \u001b[0;36mfastavro._write.write_record\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mfastavro/_write.pyx\u001b[0m in \u001b[0;36mfastavro._write.write_data\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mfastavro/_write.pyx\u001b[0m in \u001b[0;36mfastavro._write.write_union\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: 1 (type <class 'int'>) do not match ['null', 'string'] on field is_start"
     ]
    }
   ],
   "source": [
    "test6_uintc_fg = fs.create_feature_group(name=\"test6_uintc_fg\",\n",
    "                                   version=1,\n",
    "                                   primary_key=[\"ride_id\"],   \n",
    "                                   description=\"test6_uintc_fg\")   \n",
    "test6_uintc_fg.save(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cb5b3840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 41078 entries, 0 to 41077\n",
      "Data columns (total 11 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   ride_id            41078 non-null  int64  \n",
      " 1   is_start           41078 non-null  uint64 \n",
      " 2   pickup_datetime    41078 non-null  object \n",
      " 3   dropoff_datetime   41078 non-null  int64  \n",
      " 4   pickup_longitude   41078 non-null  float64\n",
      " 5   pickup_latitude    41078 non-null  float64\n",
      " 6   dropoff_longitude  41078 non-null  float64\n",
      " 7   dropoff_latitude   41078 non-null  float64\n",
      " 8   passenger_count    41078 non-null  int64  \n",
      " 9   taxi_id            41078 non-null  int64  \n",
      " 10  driver_id          41078 non-null  int64  \n",
      "dtypes: float64(4), int64(5), object(1), uint64(1)\n",
      "memory usage: 3.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df.is_start = df.is_start.astype(np.uint)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5bd3f494",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "1 (type <class 'int'>) do not match ['null', 'string'] on field is_start",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-a861bd1118dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m                                    \u001b[0mprimary_key\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ride_id\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                    description=\"test6_uint_fg\")   \n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtest6_uint_fg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/srv/hops/anaconda/envs/theenv/lib/python3.8/site-packages/hsfs/feature_group.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, features, write_options)\u001b[0m\n\u001b[1;32m    859\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m         \u001b[0;31m# fg_job is used only if the python engine is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 861\u001b[0;31m         \u001b[0mfg_job\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feature_group_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_dataframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrite_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    862\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_code_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatistics_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"spark\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/hops/anaconda/envs/theenv/lib/python3.8/site-packages/hsfs/core/feature_group_engine.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, feature_group, feature_dataframe, write_options)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0monline_write_options\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_kafka_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrite_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         return engine.get_instance().save_dataframe(\n\u001b[0m\u001b[1;32m     66\u001b[0m             \u001b[0mfeature_group\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfeature_dataframe\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/hops/anaconda/envs/theenv/lib/python3.8/site-packages/hsfs/engine/python.py\u001b[0m in \u001b[0;36msave_dataframe\u001b[0;34m(self, feature_group, dataframe, operation, online_enabled, storage, offline_write_options, online_write_options, validation_id)\u001b[0m\n\u001b[1;32m    372\u001b[0m     ):\n\u001b[1;32m    373\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfeature_group\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 374\u001b[0;31m             return self._write_dataframe_kafka(\n\u001b[0m\u001b[1;32m    375\u001b[0m                 \u001b[0mfeature_group\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffline_write_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m             )\n",
      "\u001b[0;32m/srv/hops/anaconda/envs/theenv/lib/python3.8/site-packages/hsfs/engine/python.py\u001b[0m in \u001b[0;36m_write_dataframe_kafka\u001b[0;34m(self, feature_group, dataframe, offline_write_options)\u001b[0m\n\u001b[1;32m    695\u001b[0m             \u001b[0;31m# encode feature row\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    696\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0moutf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 697\u001b[0;31m                 \u001b[0mwriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    698\u001b[0m                 \u001b[0mencoded_row\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/hops/anaconda/envs/theenv/lib/python3.8/site-packages/hsfs/engine/python.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(record, outf)\u001b[0m\n\u001b[1;32m    745\u001b[0m             \u001b[0mschema\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwriter_schema\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m             \u001b[0mparsed_schema\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_schema\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mschemaless_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparsed_schema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m         \u001b[0mparsed_schema\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mavro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwriter_schema\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mfastavro/_write.pyx\u001b[0m in \u001b[0;36mfastavro._write.schemaless_writer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mfastavro/_write.pyx\u001b[0m in \u001b[0;36mfastavro._write.write_data\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mfastavro/_write.pyx\u001b[0m in \u001b[0;36mfastavro._write.write_record\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mfastavro/_write.pyx\u001b[0m in \u001b[0;36mfastavro._write.write_data\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mfastavro/_write.pyx\u001b[0m in \u001b[0;36mfastavro._write.write_union\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: 1 (type <class 'int'>) do not match ['null', 'string'] on field is_start"
     ]
    }
   ],
   "source": [
    "test6_uint_fg = fs.create_feature_group(name=\"test6_uint_fg\",\n",
    "                                   version=1,\n",
    "                                   primary_key=[\"ride_id\"],   \n",
    "                                   description=\"test6_uint_fg\")   \n",
    "test6_uint_fg.save(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2997d2e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 41078 entries, 0 to 41077\n",
      "Data columns (total 11 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   ride_id            41078 non-null  int64  \n",
      " 1   is_start           41078 non-null  int64  \n",
      " 2   pickup_datetime    41078 non-null  object \n",
      " 3   dropoff_datetime   41078 non-null  int64  \n",
      " 4   pickup_longitude   41078 non-null  float64\n",
      " 5   pickup_latitude    41078 non-null  float64\n",
      " 6   dropoff_longitude  41078 non-null  float64\n",
      " 7   dropoff_latitude   41078 non-null  float64\n",
      " 8   passenger_count    41078 non-null  int64  \n",
      " 9   taxi_id            41078 non-null  int64  \n",
      " 10  driver_id          41078 non-null  int64  \n",
      "dtypes: float64(4), int64(6), object(1)\n",
      "memory usage: 3.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df.is_start = df.is_start.astype(np.longlong)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cf67e3b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching offline feature group backfill job...\n",
      "Backfill Job started successfully, you can follow the progress at https://hopsworks.glassfish.service.consul:8182/p/123/jobs/named/test6_longlong_fg_1_offline_fg_backfill/executions\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<hsfs.core.job.Job at 0x7f9be5a6c760>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test6_longlong_fg = fs.create_feature_group(name=\"test6_longlong_fg\",\n",
    "                                   version=1,\n",
    "                                   primary_key=[\"ride_id\"],   \n",
    "                                   description=\"test6_longlong_fg\")   \n",
    "test6_longlong_fg.save(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "bff4e21d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 41078 entries, 0 to 41077\n",
      "Data columns (total 11 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   ride_id            41078 non-null  int64  \n",
      " 1   is_start           41078 non-null  uint64 \n",
      " 2   pickup_datetime    41078 non-null  object \n",
      " 3   dropoff_datetime   41078 non-null  int64  \n",
      " 4   pickup_longitude   41078 non-null  float64\n",
      " 5   pickup_latitude    41078 non-null  float64\n",
      " 6   dropoff_longitude  41078 non-null  float64\n",
      " 7   dropoff_latitude   41078 non-null  float64\n",
      " 8   passenger_count    41078 non-null  int64  \n",
      " 9   taxi_id            41078 non-null  int64  \n",
      " 10  driver_id          41078 non-null  int64  \n",
      "dtypes: float64(4), int64(5), object(1), uint64(1)\n",
      "memory usage: 3.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df.is_start = df.is_start.astype(np.ulonglong)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "05265adc",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "1 (type <class 'int'>) do not match ['null', 'string'] on field is_start",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-e3c74471c237>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m                                    \u001b[0mprimary_key\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ride_id\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                    description=\"test6_ulonglong_fg\")   \n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtest6_ulonglong_fg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/srv/hops/anaconda/envs/theenv/lib/python3.8/site-packages/hsfs/feature_group.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, features, write_options)\u001b[0m\n\u001b[1;32m    859\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m         \u001b[0;31m# fg_job is used only if the python engine is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 861\u001b[0;31m         \u001b[0mfg_job\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feature_group_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_dataframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrite_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    862\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_code_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatistics_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"spark\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/hops/anaconda/envs/theenv/lib/python3.8/site-packages/hsfs/core/feature_group_engine.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, feature_group, feature_dataframe, write_options)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0monline_write_options\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_kafka_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrite_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         return engine.get_instance().save_dataframe(\n\u001b[0m\u001b[1;32m     66\u001b[0m             \u001b[0mfeature_group\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfeature_dataframe\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/hops/anaconda/envs/theenv/lib/python3.8/site-packages/hsfs/engine/python.py\u001b[0m in \u001b[0;36msave_dataframe\u001b[0;34m(self, feature_group, dataframe, operation, online_enabled, storage, offline_write_options, online_write_options, validation_id)\u001b[0m\n\u001b[1;32m    372\u001b[0m     ):\n\u001b[1;32m    373\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfeature_group\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 374\u001b[0;31m             return self._write_dataframe_kafka(\n\u001b[0m\u001b[1;32m    375\u001b[0m                 \u001b[0mfeature_group\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffline_write_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m             )\n",
      "\u001b[0;32m/srv/hops/anaconda/envs/theenv/lib/python3.8/site-packages/hsfs/engine/python.py\u001b[0m in \u001b[0;36m_write_dataframe_kafka\u001b[0;34m(self, feature_group, dataframe, offline_write_options)\u001b[0m\n\u001b[1;32m    695\u001b[0m             \u001b[0;31m# encode feature row\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    696\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0moutf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 697\u001b[0;31m                 \u001b[0mwriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    698\u001b[0m                 \u001b[0mencoded_row\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/hops/anaconda/envs/theenv/lib/python3.8/site-packages/hsfs/engine/python.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(record, outf)\u001b[0m\n\u001b[1;32m    745\u001b[0m             \u001b[0mschema\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwriter_schema\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m             \u001b[0mparsed_schema\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_schema\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mschemaless_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparsed_schema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m         \u001b[0mparsed_schema\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mavro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwriter_schema\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mfastavro/_write.pyx\u001b[0m in \u001b[0;36mfastavro._write.schemaless_writer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mfastavro/_write.pyx\u001b[0m in \u001b[0;36mfastavro._write.write_data\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mfastavro/_write.pyx\u001b[0m in \u001b[0;36mfastavro._write.write_record\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mfastavro/_write.pyx\u001b[0m in \u001b[0;36mfastavro._write.write_data\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mfastavro/_write.pyx\u001b[0m in \u001b[0;36mfastavro._write.write_union\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: 1 (type <class 'int'>) do not match ['null', 'string'] on field is_start"
     ]
    }
   ],
   "source": [
    "test6_ulonglong_fg = fs.create_feature_group(name=\"test6_ulonglong_fg\",\n",
    "                                   version=1,\n",
    "                                   primary_key=[\"ride_id\"],   \n",
    "                                   description=\"test6_ulonglong_fg\")   \n",
    "test6_ulonglong_fg.save(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "716e361f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 41078 entries, 0 to 41077\n",
      "Data columns (total 11 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   ride_id            41078 non-null  int64  \n",
      " 1   is_start           41078 non-null  float16\n",
      " 2   pickup_datetime    41078 non-null  object \n",
      " 3   dropoff_datetime   41078 non-null  int64  \n",
      " 4   pickup_longitude   41078 non-null  float64\n",
      " 5   pickup_latitude    41078 non-null  float64\n",
      " 6   dropoff_longitude  41078 non-null  float64\n",
      " 7   dropoff_latitude   41078 non-null  float64\n",
      " 8   passenger_count    41078 non-null  int64  \n",
      " 9   taxi_id            41078 non-null  int64  \n",
      " 10  driver_id          41078 non-null  int64  \n",
      "dtypes: float16(1), float64(4), int64(5), object(1)\n",
      "memory usage: 3.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.is_start = df.is_start.astype(np.float16)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4270eb6a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "1.0 (type <class 'float'>) do not match ['null', 'string'] on field is_start",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-a048c24ad561>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m                                    \u001b[0mprimary_key\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ride_id\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                    description=\"test6_float16_fg\")   \n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtest6_float16_fg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/srv/hops/anaconda/envs/theenv/lib/python3.8/site-packages/hsfs/feature_group.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, features, write_options)\u001b[0m\n\u001b[1;32m    859\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m         \u001b[0;31m# fg_job is used only if the python engine is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 861\u001b[0;31m         \u001b[0mfg_job\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feature_group_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_dataframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrite_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    862\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_code_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatistics_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"spark\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/hops/anaconda/envs/theenv/lib/python3.8/site-packages/hsfs/core/feature_group_engine.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, feature_group, feature_dataframe, write_options)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0monline_write_options\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_kafka_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrite_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         return engine.get_instance().save_dataframe(\n\u001b[0m\u001b[1;32m     66\u001b[0m             \u001b[0mfeature_group\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfeature_dataframe\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/hops/anaconda/envs/theenv/lib/python3.8/site-packages/hsfs/engine/python.py\u001b[0m in \u001b[0;36msave_dataframe\u001b[0;34m(self, feature_group, dataframe, operation, online_enabled, storage, offline_write_options, online_write_options, validation_id)\u001b[0m\n\u001b[1;32m    372\u001b[0m     ):\n\u001b[1;32m    373\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfeature_group\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 374\u001b[0;31m             return self._write_dataframe_kafka(\n\u001b[0m\u001b[1;32m    375\u001b[0m                 \u001b[0mfeature_group\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffline_write_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m             )\n",
      "\u001b[0;32m/srv/hops/anaconda/envs/theenv/lib/python3.8/site-packages/hsfs/engine/python.py\u001b[0m in \u001b[0;36m_write_dataframe_kafka\u001b[0;34m(self, feature_group, dataframe, offline_write_options)\u001b[0m\n\u001b[1;32m    695\u001b[0m             \u001b[0;31m# encode feature row\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    696\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0moutf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 697\u001b[0;31m                 \u001b[0mwriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    698\u001b[0m                 \u001b[0mencoded_row\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/hops/anaconda/envs/theenv/lib/python3.8/site-packages/hsfs/engine/python.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(record, outf)\u001b[0m\n\u001b[1;32m    745\u001b[0m             \u001b[0mschema\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwriter_schema\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m             \u001b[0mparsed_schema\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_schema\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mschemaless_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparsed_schema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m         \u001b[0mparsed_schema\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mavro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwriter_schema\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mfastavro/_write.pyx\u001b[0m in \u001b[0;36mfastavro._write.schemaless_writer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mfastavro/_write.pyx\u001b[0m in \u001b[0;36mfastavro._write.write_data\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mfastavro/_write.pyx\u001b[0m in \u001b[0;36mfastavro._write.write_record\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mfastavro/_write.pyx\u001b[0m in \u001b[0;36mfastavro._write.write_data\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mfastavro/_write.pyx\u001b[0m in \u001b[0;36mfastavro._write.write_union\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: 1.0 (type <class 'float'>) do not match ['null', 'string'] on field is_start"
     ]
    }
   ],
   "source": [
    "test6_float16_fg = fs.create_feature_group(name=\"test6_float16_fg\",\n",
    "                                   version=1,\n",
    "                                   primary_key=[\"ride_id\"],   \n",
    "                                   description=\"test6_float16_fg\")   \n",
    "test6_float16_fg.save(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5ca87334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 41078 entries, 0 to 41077\n",
      "Data columns (total 11 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   ride_id            41078 non-null  int64  \n",
      " 1   is_start           41078 non-null  float32\n",
      " 2   pickup_datetime    41078 non-null  object \n",
      " 3   dropoff_datetime   41078 non-null  int64  \n",
      " 4   pickup_longitude   41078 non-null  float64\n",
      " 5   pickup_latitude    41078 non-null  float64\n",
      " 6   dropoff_longitude  41078 non-null  float64\n",
      " 7   dropoff_latitude   41078 non-null  float64\n",
      " 8   passenger_count    41078 non-null  int64  \n",
      " 9   taxi_id            41078 non-null  int64  \n",
      " 10  driver_id          41078 non-null  int64  \n",
      "dtypes: float32(1), float64(4), int64(5), object(1)\n",
      "memory usage: 3.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.is_start = df.is_start.astype(np.single)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3fea3305",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching offline feature group backfill job...\n",
      "Backfill Job started successfully, you can follow the progress at https://hopsworks.glassfish.service.consul:8182/p/123/jobs/named/test6_single_fg_1_offline_fg_backfill/executions\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<hsfs.core.job.Job at 0x7f9be520a400>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test6_single_fg = fs.create_feature_group(name=\"test6_single_fg\",\n",
    "                                   version=1,\n",
    "                                   primary_key=[\"ride_id\"],   \n",
    "                                   description=\"test6_single_fg\")   \n",
    "test6_single_fg.save(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6864d637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 41078 entries, 0 to 41077\n",
      "Data columns (total 11 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   ride_id            41078 non-null  int64  \n",
      " 1   is_start           41078 non-null  float64\n",
      " 2   pickup_datetime    41078 non-null  object \n",
      " 3   dropoff_datetime   41078 non-null  int64  \n",
      " 4   pickup_longitude   41078 non-null  float64\n",
      " 5   pickup_latitude    41078 non-null  float64\n",
      " 6   dropoff_longitude  41078 non-null  float64\n",
      " 7   dropoff_latitude   41078 non-null  float64\n",
      " 8   passenger_count    41078 non-null  int64  \n",
      " 9   taxi_id            41078 non-null  int64  \n",
      " 10  driver_id          41078 non-null  int64  \n",
      "dtypes: float64(5), int64(5), object(1)\n",
      "memory usage: 3.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df.is_start = df.is_start.astype(np.double)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "05cf6588",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching offline feature group backfill job...\n",
      "Backfill Job started successfully, you can follow the progress at https://hopsworks.glassfish.service.consul:8182/p/123/jobs/named/test6_double_fg_1_offline_fg_backfill/executions\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<hsfs.core.job.Job at 0x7f9be5a5bf40>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test6_double_fg = fs.create_feature_group(name=\"test6_double_fg\",\n",
    "                                   version=1,\n",
    "                                   primary_key=[\"ride_id\"],   \n",
    "                                   description=\"test6_double_fg\")   \n",
    "test6_double_fg.save(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "05fe09ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 41078 entries, 0 to 41077\n",
      "Data columns (total 11 columns):\n",
      " #   Column             Non-Null Count  Dtype   \n",
      "---  ------             --------------  -----   \n",
      " 0   ride_id            41078 non-null  int64   \n",
      " 1   is_start           41078 non-null  float128\n",
      " 2   pickup_datetime    41078 non-null  object  \n",
      " 3   dropoff_datetime   41078 non-null  int64   \n",
      " 4   pickup_longitude   41078 non-null  float64 \n",
      " 5   pickup_latitude    41078 non-null  float64 \n",
      " 6   dropoff_longitude  41078 non-null  float64 \n",
      " 7   dropoff_latitude   41078 non-null  float64 \n",
      " 8   passenger_count    41078 non-null  int64   \n",
      " 9   taxi_id            41078 non-null  int64   \n",
      " 10  driver_id          41078 non-null  int64   \n",
      "dtypes: float128(1), float64(4), int64(5), object(1)\n",
      "memory usage: 4.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.is_start = df.is_start.astype(np.longdouble)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "02dc0742",
   "metadata": {},
   "outputs": [
    {
     "ename": "ArrowNotImplementedError",
     "evalue": "Unsupported numpy type 13",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mArrowNotImplementedError\u001b[0m                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-61-26cd92a08d70>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m                                    \u001b[0mprimary_key\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ride_id\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                    description=\"test6_longdouble_fg\")   \n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtest6_longdouble_fg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/srv/hops/anaconda/envs/theenv/lib/python3.8/site-packages/hsfs/feature_group.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, features, write_options)\u001b[0m\n\u001b[1;32m    859\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m         \u001b[0;31m# fg_job is used only if the python engine is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 861\u001b[0;31m         \u001b[0mfg_job\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feature_group_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_dataframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrite_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    862\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_code_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatistics_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"spark\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/hops/anaconda/envs/theenv/lib/python3.8/site-packages/hsfs/core/feature_group_engine.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, feature_group, feature_dataframe, write_options)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_group\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0;31m# User didn't provide a schema. extract it from the dataframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m             feature_group._features = engine.get_instance().parse_schema_feature_group(\n\u001b[0m\u001b[1;32m     35\u001b[0m                 \u001b[0mfeature_dataframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             )\n",
      "\u001b[0;32m/srv/hops/anaconda/envs/theenv/lib/python3.8/site-packages/hsfs/engine/python.py\u001b[0m in \u001b[0;36mparse_schema_feature_group\u001b[0;34m(self, dataframe)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparse_schema_feature_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0marrow_schema\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSchema\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pandas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m         return [\n\u001b[1;32m    309\u001b[0m             feature.Feature(\n",
      "\u001b[0;32m/srv/hops/anaconda/envs/theenv/lib/python3.8/site-packages/pyarrow/types.pxi\u001b[0m in \u001b[0;36mpyarrow.lib.Schema.from_pandas\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/srv/hops/anaconda/envs/theenv/lib/python3.8/site-packages/pyarrow/pandas_compat.py\u001b[0m in \u001b[0;36mdataframe_to_types\u001b[0;34m(df, preserve_index, columns)\u001b[0m\n\u001b[1;32m    530\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m             \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_datetimetz_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mtype_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ndarray_to_arrow_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtype_\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m                 \u001b[0mtype_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrom_pandas\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/hops/anaconda/envs/theenv/lib/python3.8/site-packages/pyarrow/array.pxi\u001b[0m in \u001b[0;36mpyarrow.lib._ndarray_to_arrow_type\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/srv/hops/anaconda/envs/theenv/lib/python3.8/site-packages/pyarrow/array.pxi\u001b[0m in \u001b[0;36mpyarrow.lib._ndarray_to_type\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/srv/hops/anaconda/envs/theenv/lib/python3.8/site-packages/pyarrow/error.pxi\u001b[0m in \u001b[0;36mpyarrow.lib.check_status\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mArrowNotImplementedError\u001b[0m: Unsupported numpy type 13"
     ]
    }
   ],
   "source": [
    "test6_longdouble_fg = fs.create_feature_group(name=\"test6_longdouble_fg\",\n",
    "                                   version=1,\n",
    "                                   primary_key=[\"ride_id\"],   \n",
    "                                   description=\"test6_longdouble_fg\")   \n",
    "test6_longdouble_fg.save(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "48b7e02c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 41078 entries, 0 to 41077\n",
      "Data columns (total 11 columns):\n",
      " #   Column             Non-Null Count  Dtype    \n",
      "---  ------             --------------  -----    \n",
      " 0   ride_id            41078 non-null  int64    \n",
      " 1   is_start           41078 non-null  complex64\n",
      " 2   pickup_datetime    41078 non-null  object   \n",
      " 3   dropoff_datetime   41078 non-null  int64    \n",
      " 4   pickup_longitude   41078 non-null  float64  \n",
      " 5   pickup_latitude    41078 non-null  float64  \n",
      " 6   dropoff_longitude  41078 non-null  float64  \n",
      " 7   dropoff_latitude   41078 non-null  float64  \n",
      " 8   passenger_count    41078 non-null  int64    \n",
      " 9   taxi_id            41078 non-null  int64    \n",
      " 10  driver_id          41078 non-null  int64    \n",
      "dtypes: complex64(1), float64(4), int64(5), object(1)\n",
      "memory usage: 3.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df.is_start = df.is_start.astype(np.csingle)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e0d35ee6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ArrowNotImplementedError",
     "evalue": "Unsupported numpy type 14",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mArrowNotImplementedError\u001b[0m                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-edcf5d2ee222>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m                                    \u001b[0mprimary_key\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ride_id\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                    description=\"test6_csingle_fg\")   \n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtest6_csingle_fg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/srv/hops/anaconda/envs/theenv/lib/python3.8/site-packages/hsfs/feature_group.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, features, write_options)\u001b[0m\n\u001b[1;32m    859\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m         \u001b[0;31m# fg_job is used only if the python engine is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 861\u001b[0;31m         \u001b[0mfg_job\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feature_group_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_dataframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrite_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    862\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_code_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatistics_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"spark\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/hops/anaconda/envs/theenv/lib/python3.8/site-packages/hsfs/core/feature_group_engine.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, feature_group, feature_dataframe, write_options)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_group\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0;31m# User didn't provide a schema. extract it from the dataframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m             feature_group._features = engine.get_instance().parse_schema_feature_group(\n\u001b[0m\u001b[1;32m     35\u001b[0m                 \u001b[0mfeature_dataframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             )\n",
      "\u001b[0;32m/srv/hops/anaconda/envs/theenv/lib/python3.8/site-packages/hsfs/engine/python.py\u001b[0m in \u001b[0;36mparse_schema_feature_group\u001b[0;34m(self, dataframe)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparse_schema_feature_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0marrow_schema\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSchema\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pandas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m         return [\n\u001b[1;32m    309\u001b[0m             feature.Feature(\n",
      "\u001b[0;32m/srv/hops/anaconda/envs/theenv/lib/python3.8/site-packages/pyarrow/types.pxi\u001b[0m in \u001b[0;36mpyarrow.lib.Schema.from_pandas\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/srv/hops/anaconda/envs/theenv/lib/python3.8/site-packages/pyarrow/pandas_compat.py\u001b[0m in \u001b[0;36mdataframe_to_types\u001b[0;34m(df, preserve_index, columns)\u001b[0m\n\u001b[1;32m    530\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m             \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_datetimetz_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mtype_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ndarray_to_arrow_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtype_\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m                 \u001b[0mtype_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrom_pandas\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/hops/anaconda/envs/theenv/lib/python3.8/site-packages/pyarrow/array.pxi\u001b[0m in \u001b[0;36mpyarrow.lib._ndarray_to_arrow_type\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/srv/hops/anaconda/envs/theenv/lib/python3.8/site-packages/pyarrow/array.pxi\u001b[0m in \u001b[0;36mpyarrow.lib._ndarray_to_type\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/srv/hops/anaconda/envs/theenv/lib/python3.8/site-packages/pyarrow/error.pxi\u001b[0m in \u001b[0;36mpyarrow.lib.check_status\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mArrowNotImplementedError\u001b[0m: Unsupported numpy type 14"
     ]
    }
   ],
   "source": [
    "test6_csingle_fg = fs.create_feature_group(name=\"test6_csingle_fg\",\n",
    "                                   version=1,\n",
    "                                   primary_key=[\"ride_id\"],   \n",
    "                                   description=\"test6_csingle_fg\")   \n",
    "test6_csingle_fg.save(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "556f9496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 41078 entries, 0 to 41077\n",
      "Data columns (total 11 columns):\n",
      " #   Column             Non-Null Count  Dtype     \n",
      "---  ------             --------------  -----     \n",
      " 0   ride_id            41078 non-null  int64     \n",
      " 1   is_start           41078 non-null  complex128\n",
      " 2   pickup_datetime    41078 non-null  object    \n",
      " 3   dropoff_datetime   41078 non-null  int64     \n",
      " 4   pickup_longitude   41078 non-null  float64   \n",
      " 5   pickup_latitude    41078 non-null  float64   \n",
      " 6   dropoff_longitude  41078 non-null  float64   \n",
      " 7   dropoff_latitude   41078 non-null  float64   \n",
      " 8   passenger_count    41078 non-null  int64     \n",
      " 9   taxi_id            41078 non-null  int64     \n",
      " 10  driver_id          41078 non-null  int64     \n",
      "dtypes: complex128(1), float64(4), int64(5), object(1)\n",
      "memory usage: 4.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.is_start = df.is_start.astype(np.cdouble)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3e7dbb34",
   "metadata": {},
   "outputs": [
    {
     "ename": "ArrowNotImplementedError",
     "evalue": "Unsupported numpy type 15",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mArrowNotImplementedError\u001b[0m                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-65-32ee40e2f499>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m                                    \u001b[0mprimary_key\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ride_id\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                    description=\"test6_cdouble_fg\")   \n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtest6_cdouble_fg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/srv/hops/anaconda/envs/theenv/lib/python3.8/site-packages/hsfs/feature_group.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, features, write_options)\u001b[0m\n\u001b[1;32m    859\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m         \u001b[0;31m# fg_job is used only if the python engine is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 861\u001b[0;31m         \u001b[0mfg_job\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feature_group_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_dataframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrite_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    862\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_code_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatistics_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"spark\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/hops/anaconda/envs/theenv/lib/python3.8/site-packages/hsfs/core/feature_group_engine.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, feature_group, feature_dataframe, write_options)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_group\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0;31m# User didn't provide a schema. extract it from the dataframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m             feature_group._features = engine.get_instance().parse_schema_feature_group(\n\u001b[0m\u001b[1;32m     35\u001b[0m                 \u001b[0mfeature_dataframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             )\n",
      "\u001b[0;32m/srv/hops/anaconda/envs/theenv/lib/python3.8/site-packages/hsfs/engine/python.py\u001b[0m in \u001b[0;36mparse_schema_feature_group\u001b[0;34m(self, dataframe)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparse_schema_feature_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0marrow_schema\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSchema\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pandas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m         return [\n\u001b[1;32m    309\u001b[0m             feature.Feature(\n",
      "\u001b[0;32m/srv/hops/anaconda/envs/theenv/lib/python3.8/site-packages/pyarrow/types.pxi\u001b[0m in \u001b[0;36mpyarrow.lib.Schema.from_pandas\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/srv/hops/anaconda/envs/theenv/lib/python3.8/site-packages/pyarrow/pandas_compat.py\u001b[0m in \u001b[0;36mdataframe_to_types\u001b[0;34m(df, preserve_index, columns)\u001b[0m\n\u001b[1;32m    530\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m             \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_datetimetz_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mtype_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ndarray_to_arrow_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtype_\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m                 \u001b[0mtype_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrom_pandas\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/hops/anaconda/envs/theenv/lib/python3.8/site-packages/pyarrow/array.pxi\u001b[0m in \u001b[0;36mpyarrow.lib._ndarray_to_arrow_type\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/srv/hops/anaconda/envs/theenv/lib/python3.8/site-packages/pyarrow/array.pxi\u001b[0m in \u001b[0;36mpyarrow.lib._ndarray_to_type\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/srv/hops/anaconda/envs/theenv/lib/python3.8/site-packages/pyarrow/error.pxi\u001b[0m in \u001b[0;36mpyarrow.lib.check_status\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mArrowNotImplementedError\u001b[0m: Unsupported numpy type 15"
     ]
    }
   ],
   "source": [
    "test6_cdouble_fg = fs.create_feature_group(name=\"test6_cdouble_fg\",\n",
    "                                   version=1,\n",
    "                                   primary_key=[\"ride_id\"],   \n",
    "                                   description=\"test6_cdouble_fg\")   \n",
    "test6_cdouble_fg.save(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "54ae9938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 41078 entries, 0 to 41077\n",
      "Data columns (total 11 columns):\n",
      " #   Column             Non-Null Count  Dtype     \n",
      "---  ------             --------------  -----     \n",
      " 0   ride_id            41078 non-null  int64     \n",
      " 1   is_start           41078 non-null  complex256\n",
      " 2   pickup_datetime    41078 non-null  object    \n",
      " 3   dropoff_datetime   41078 non-null  int64     \n",
      " 4   pickup_longitude   41078 non-null  float64   \n",
      " 5   pickup_latitude    41078 non-null  float64   \n",
      " 6   dropoff_longitude  41078 non-null  float64   \n",
      " 7   dropoff_latitude   41078 non-null  float64   \n",
      " 8   passenger_count    41078 non-null  int64     \n",
      " 9   taxi_id            41078 non-null  int64     \n",
      " 10  driver_id          41078 non-null  int64     \n",
      "dtypes: complex256(1), float64(4), int64(5), object(1)\n",
      "memory usage: 4.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df.is_start = df.is_start.astype(np.clongdouble)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "10c44829",
   "metadata": {},
   "outputs": [
    {
     "ename": "ArrowNotImplementedError",
     "evalue": "Unsupported numpy type 16",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mArrowNotImplementedError\u001b[0m                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-67-d458ba20c9d5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m                                    \u001b[0mprimary_key\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ride_id\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                    description=\"test6_clongdouble_fg\")   \n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtest6_clongdouble_fg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/srv/hops/anaconda/envs/theenv/lib/python3.8/site-packages/hsfs/feature_group.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, features, write_options)\u001b[0m\n\u001b[1;32m    859\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m         \u001b[0;31m# fg_job is used only if the python engine is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 861\u001b[0;31m         \u001b[0mfg_job\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feature_group_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_dataframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrite_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    862\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_code_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatistics_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"spark\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/hops/anaconda/envs/theenv/lib/python3.8/site-packages/hsfs/core/feature_group_engine.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, feature_group, feature_dataframe, write_options)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_group\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0;31m# User didn't provide a schema. extract it from the dataframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m             feature_group._features = engine.get_instance().parse_schema_feature_group(\n\u001b[0m\u001b[1;32m     35\u001b[0m                 \u001b[0mfeature_dataframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             )\n",
      "\u001b[0;32m/srv/hops/anaconda/envs/theenv/lib/python3.8/site-packages/hsfs/engine/python.py\u001b[0m in \u001b[0;36mparse_schema_feature_group\u001b[0;34m(self, dataframe)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparse_schema_feature_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0marrow_schema\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSchema\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pandas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m         return [\n\u001b[1;32m    309\u001b[0m             feature.Feature(\n",
      "\u001b[0;32m/srv/hops/anaconda/envs/theenv/lib/python3.8/site-packages/pyarrow/types.pxi\u001b[0m in \u001b[0;36mpyarrow.lib.Schema.from_pandas\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/srv/hops/anaconda/envs/theenv/lib/python3.8/site-packages/pyarrow/pandas_compat.py\u001b[0m in \u001b[0;36mdataframe_to_types\u001b[0;34m(df, preserve_index, columns)\u001b[0m\n\u001b[1;32m    530\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m             \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_datetimetz_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mtype_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ndarray_to_arrow_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtype_\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m                 \u001b[0mtype_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrom_pandas\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/hops/anaconda/envs/theenv/lib/python3.8/site-packages/pyarrow/array.pxi\u001b[0m in \u001b[0;36mpyarrow.lib._ndarray_to_arrow_type\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/srv/hops/anaconda/envs/theenv/lib/python3.8/site-packages/pyarrow/array.pxi\u001b[0m in \u001b[0;36mpyarrow.lib._ndarray_to_type\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/srv/hops/anaconda/envs/theenv/lib/python3.8/site-packages/pyarrow/error.pxi\u001b[0m in \u001b[0;36mpyarrow.lib.check_status\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mArrowNotImplementedError\u001b[0m: Unsupported numpy type 16"
     ]
    }
   ],
   "source": [
    "test6_clongdouble_fg = fs.create_feature_group(name=\"test6_clongdouble_fg\",\n",
    "                                   version=1,\n",
    "                                   primary_key=[\"ride_id\"],   \n",
    "                                   description=\"test6_clongdouble_fg\")   \n",
    "test6_clongdouble_fg.save(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}